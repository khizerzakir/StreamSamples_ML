{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 3: Random Forest Algorithm\n",
    "\n",
    "**Authors**: __Khizer Zakir & Rodrigo Brust Santos__\n",
    "\n",
    "__November 2023__\n",
    "\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#graphic and charts\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#machine learning\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#spatial libraries\n",
    "import geopandas as gpd\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. Feedback\n",
    "\n",
    "1. Hyperparameter Setting\n",
    "\n",
    "\n",
    "2. Model Calibration\n",
    "\n",
    "\n",
    "3.  Variable Selection\n",
    "\n",
    "\n",
    "4. Model Evaluation\n",
    "\n",
    "\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>Ag (ppm)</th>\n",
       "      <th>Al (%)</th>\n",
       "      <th>As (ppm)</th>\n",
       "      <th>Ba (ppm)</th>\n",
       "      <th>Be (ppm)</th>\n",
       "      <th>Bi (ppm)</th>\n",
       "      <th>Ca (%)</th>\n",
       "      <th>Cd (ppm)</th>\n",
       "      <th>...</th>\n",
       "      <th>Sr (ppm)</th>\n",
       "      <th>Th (ppm)</th>\n",
       "      <th>Ti (%)</th>\n",
       "      <th>U (ppm)</th>\n",
       "      <th>V (ppm)</th>\n",
       "      <th>W (ppm)</th>\n",
       "      <th>Y (ppm)</th>\n",
       "      <th>Zn (ppm)</th>\n",
       "      <th>Zr (ppm)</th>\n",
       "      <th>basin_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>248757</td>\n",
       "      <td>7972050</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.63</td>\n",
       "      <td>4.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.70</td>\n",
       "      <td>73</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.15</td>\n",
       "      <td>27</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>244460</td>\n",
       "      <td>7973135</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.94</td>\n",
       "      <td>58</td>\n",
       "      <td>0.3</td>\n",
       "      <td>23.90</td>\n",
       "      <td>58</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x        y  Ag (ppm)  Al (%)  As (ppm)  Ba (ppm)  Be (ppm)  Bi (ppm)  \\\n",
       "0  248757  7972050      0.03    2.63       4.0      76.0       1.0      0.31   \n",
       "1  244460  7973135      0.02    1.93       2.0      84.0       1.7      0.29   \n",
       "\n",
       "   Ca (%)  Cd (ppm)  ...  Sr (ppm)  Th (ppm)  Ti (%)  U (ppm)  V (ppm)  \\\n",
       "0    0.05      0.03  ...       3.3       7.4    0.03     0.70       73   \n",
       "1    0.04      0.01  ...       3.1       8.2    0.06     0.94       58   \n",
       "\n",
       "   W (ppm)  Y (ppm)  Zn (ppm)  Zr (ppm)  basin_id  \n",
       "0      0.3    13.15        27       6.3         2  \n",
       "1      0.3    23.90        58       6.9         3  \n",
       "\n",
       "[2 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading data frame\n",
    "df = pd.read_csv('../dataset/stream_samples_basin_id.csv')\n",
    "\n",
    "#removing columns that wont be used\n",
    "df.drop(columns = ['geometry', 'index_right'], inplace = True)\n",
    "\n",
    "df.rename(columns = {'OBJECTID':'basin_id'}, inplace = True)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable that we will predict\n",
    "Y_column = 'Zn (ppm)'\n",
    "\n",
    "#explanatory variables\n",
    "X_columns = list(df.iloc[:, :-1])\n",
    "\n",
    "#dropping Zn from our explanatory variables\n",
    "X_columns.remove('Zn (ppm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating the X and Y dataset and transforming to numpy array\n",
    "X, Y = df[X_columns].to_numpy(), df[Y_column].to_numpy()\n",
    "\n",
    "#defining the watershed number as the group\n",
    "groups = df['basin_id'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How we did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_size = 0.3 #setting the test size. \n",
    "n_splits = 4   #setting the number of splits, arbitrarly.\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "basin_kfold = group_kfold.split(X, Y, groups)\n",
    "\n",
    "# Create a nested list of train and test indices for each fold\n",
    "train_indices, test_indices = [list(traintest) for traintest in zip(*basin_kfold)]\n",
    "\n",
    "basin_cv = [*zip(train_indices,test_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.57\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "linear_clf = LinearRegression().fit(X, Y)\n",
    "\n",
    "# fit and predict at the same time consdering the cv = basin_cv takes care of the data splitting\n",
    "\n",
    "y_pred = cross_val_predict(linear_clf, X, Y, cv=basin_cv, groups=groups)\n",
    "\n",
    "r2 = r2_score(Y, y_pred)\n",
    "\n",
    "print('R2: ',round(r2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - Index: 1  0.53\n",
      "RMSE: 15.31\n",
      "MSE: 234.27\n",
      "R2 - Index: 2  0.62\n",
      "RMSE: 14.14\n",
      "MSE: 199.84\n",
      "R2 - Index: 3  0.55\n",
      "RMSE: 11.66\n",
      "MSE: 135.84\n"
     ]
    }
   ],
   "source": [
    "# Create a GroupKFold object with the desired number of splits (k)\n",
    "k = 4\n",
    "group_kfold_two = GroupKFold(n_splits=k)\n",
    "\n",
    "# Specify the fold you want to use (fold_index should be less than k)\n",
    "fold_index = [1,2,3]\n",
    "\n",
    "r2_scores, mse_scores, rmse_scores = [], [], []\n",
    "\n",
    "for i in fold_index:\n",
    "\n",
    "    # Get indices for the specified fold\n",
    "    train_index, test_index = list(group_kfold_two.split(X, Y, groups))[i - 1]\n",
    "\n",
    "    #print('Train-Test Shapes', train_index.shape, test_index.shape)\n",
    "\n",
    "    # Use the indices to get the training and testing sets\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "\n",
    "    #print('X Train-Test Shapes', X_train.shape, X_test.shape)\n",
    "    \n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    #print('Y Train-Test Shapes', y_train.shape, y_test.shape)\n",
    "\n",
    "    # Create a linear regression model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    y_pred_two = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    r2 = r2_score(y_test, y_pred_two)\n",
    "    rmse = mean_squared_error(y_test, y_pred_two, squared=False)\n",
    "    mse = mean_squared_error(y_test, y_pred_two)\n",
    "\n",
    "    print(f'R2 - Index: {i} ',round(r2,2))\n",
    "    print(f'RMSE:', round(rmse,2))\n",
    "    print(f'MSE:', round(mse,2))\n",
    "\n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.56, 13.7, 189.99)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(r2_scores),2), round(np.mean(rmse_scores),2), round(np.mean(mse_scores),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 1 0.5959173014095739 14.19358526782089 201.45786275490218\n",
      "Index 2 0.6461940686823625 13.5744030918268 184.26441929939702\n",
      "Index 3 0.5278142409741016 11.880613713672371 141.14898221350003\n"
     ]
    }
   ],
   "source": [
    "#using the optimal learning rate\n",
    "r_rmse, r_mse, r_r2 = [], [], []\n",
    "for i in fold_index:\n",
    "\n",
    "    # Get indices for the specified fold\n",
    "    train_index, test_index = list(group_kfold_two.split(X, Y, groups))[i - 1]\n",
    "\n",
    "    #print('Train-Test Shapes', train_index.shape, test_index.shape)\n",
    "\n",
    "    # Use the indices to get the training and testing sets\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "\n",
    "    #print('X Train-Test Shapes', X_train.shape, X_test.shape)\n",
    "    \n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    #print('Y Train-Test Shapes', y_train.shape, y_test.shape)\n",
    "\n",
    "    elastmodel = Ridge(alpha=4.83)\n",
    "    \n",
    "    elastmodel.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_ridge = elastmodel.predict(X_test)\n",
    "        \n",
    "    # Calculate evaluation metrics\n",
    "    rmse_ridge = mean_squared_error(y_test, y_pred_ridge, squared=False)\n",
    "    mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "    r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "    r_rmse.append(rmse_ridge)\n",
    "    r_mse.append(mse_ridge)\n",
    "    r_r2.append(r2_ridge)\n",
    "\n",
    "    print(f'Index {i}', r2_ridge, rmse_ridge, mse_ridge )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.59, 13.22, 175.62)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(r_r2),2), round(np.mean(r_rmse),2), round(np.mean(r_mse),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Hyperparameter Setting\n",
    "\n",
    "â€¢ Recall what are the two most important hyperparameters. Propose a protocol that relies on the out-of-bag\n",
    "(OOB) error to tune this hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maxfeatures\n",
    "d = round(np.sqrt(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = RandomForestClassifier(n_estimators= 500, max_features=d, oob_score=True, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_features=27, n_estimators=500, oob_score=True,\n",
       "                       random_state=45)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=27, n_estimators=500, oob_score=True,\n",
       "                       random_state=45)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_features=27, n_estimators=500, oob_score=True,\n",
       "                       random_state=45)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 27,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 500,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': True,\n",
       " 'random_state': 45,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB score:  0.05\n",
      "OOB error: 0.95\n"
     ]
    }
   ],
   "source": [
    "oob_score = round(tree_clf.oob_score_,2)\n",
    "\n",
    "print('OOB score: ', oob_score )\n",
    "\n",
    "oob_error = 1 - oob_score\n",
    "print('OOB error:', oob_error )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Calibration\n",
    "\n",
    "â€¢ For the calibrated model, measure the importance of each variable. Justify the choice of the importance\n",
    "measure (why did you use this importance measure instead of another one?). Comment on the results:\n",
    "according to the importance measure you chose, what are the most discriminant variables of your dataset?\n",
    "Interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Variable Selection\n",
    "\n",
    "â€¢ Based on the feature importance analysis (previous question), conduct a selection of variables using one\n",
    "of the strategies described during the lecture. Justify your choice and recall how the selected technique\n",
    "works. Implement and run it. What is the final number of selected variables in the model? Justify if you\n",
    "need to recalibrate the forest or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Evaluation\n",
    "\n",
    "â€¢ Evaluate the test performance of the two random forest models (based on the full set of variables or\n",
    "a subset) and determine the configuration of the best model (based on the main evaluation metric you\n",
    "selected in step 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
